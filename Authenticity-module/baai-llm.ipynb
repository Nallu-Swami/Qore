{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10923387,"sourceType":"datasetVersion","datasetId":6791316}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(\"/kaggle/input/testset/Sample-Data-for-Hackathon.csv\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-v2-m3\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"BAAI/bge-reranker-v2-m3\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T17:55:59.867982Z","iopub.execute_input":"2025-03-08T17:55:59.868278Z","iopub.status.idle":"2025-03-08T17:56:32.671536Z","shell.execute_reply.started":"2025-03-08T17:55:59.868248Z","shell.execute_reply":"2025-03-08T17:56:32.670869Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47fd2409b3074c5daf5edf5e59ea1ae9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a15ca4019a4c989070fb8e7bc74321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"711a22b2442545038a11524bc7af1dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"733884b734174a7ca18c15d061944def"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/795 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84d0c38b64984ef2894cb22b18c02dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e4c1d1bfe5b46d99aef0067b1477c8c"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"question = '''\n **Question:**  \n*\"What is the most important aspect you LIKE about the ULTRA Pure Gold concept? This could include features you would want to keep for sure or elements that might drive you to buy or try it. Please provide a detailed response.\"*  \n'''\nanswers = [\n    \"It's a classic brand.\",\n    \"Taste\",\n    \"Why?\",\n    \"I have a lot to say\",\n    \"I love Michelob brand and the bottle shape and color is very appealing\",\n    \"it's michelob\",\n    \"I don't\",\n    \"Michelob ULTRA Pure Gold is distinguished by its use of organic ingredients and refreshing taste, with low calories.\",\n    \"That it had less calories\",\n    \"No response\",\n    \"Smooth taste\",\n    \"I would buy it if they were out of my regular beer. It's not bad and is more refreshing than some other light beers.\",\n    \"I don’t like it.\",\n    \"I have try it see how smoothly it goes down\",\n    \"I like michelob\",\n    \"I like the taste and it doesn't leave my gut feeling heavy\",\n    \"Quality\",\n    \"really good quality and good offerings\",\n    \"It has a smooth and refreshing taste\",\n    \"i didnt say i did\",\n    \"Low calorie and low carbs\",\n    \"The taste and quality\",\n    \"I liked the colors that were used. I also liked that it was light.\",\n    \"Better name\",\n    \"It sounds interesting\",\n    \"Its packaging is appealing right off the bat. Its rich and thick taste basically makes my mouth salivate.\",\n    \"It looks refreshing and delicious, I like the low calorie feature\",\n    \"The price\",\n    \"i like that the beer is light. It seems healthier.\",\n    \"The bottle design & fonts.\",\n    \"I don’t like anything\",\n    \"Healthier\",\n    \"It’s an ok beer\",\n    \"Love the taste it’s great and light unlike other beers\",\n    \"Test are very good.\",\n    \"85 calories\",\n    \"The taste is so smooth\",\n    \"The brand and the taste\",\n    \"Low calorie\",\n    \"the whole product was great\",\n    \"Nothing in particular\",\n    \"It's not a heavy beer\",\n    \"It is crisp and refreshing\",\n    \"Well if i will like anything about it will be the alcohol percentage it have\",\n    \"Nothing\",\n    \"I like how light it tastes\",\n    \"i like\",\n    \"It is a brand with a unique and different taste\",\n    \"None\",\n    \"Don't drink it\",\n    \"I like this new idea\",\n    \"Overall everything is good\",\n    \"I like that it's a premium light beer\",\n    \"Nothing about this jumps out at me to purchase this beer at all.\",\n    \"The bottle\",\n    \"It’s smooth making it very tasty\",\n    \"I like the commercials\",\n    \"I have never drank it but it looks smooth and good\",\n    \"I like the packaging\",\n    \"Low carbs\",\n    \"Great price. Pretty bottle. Low calorie\",\n    \"n/a\",\n    \"nothing\",\n    \"Homegrown ingredients and organic\",\n    \"I love lagers and I like the fact that it's an extra light lager.\",\n    \"Everything about it\",\n    \"Half price on the 1st of every month\",\n    \"The taste\",\n    \"It’s low calorie and low carb\",\n    \"it's low carb and light\",\n    \"I like that it has low calories and carbs.\",\n    \"I just like it.\",\n    \"Low calories and carbs\",\n    \"I enjoy the brand. Good idea.\",\n    \"Low Carb\",\n    \"Low cal and carbs\",\n    \"Nothing\",\n    \"Love the package it's low calorie great description of the beer\",\n    \"It is very tasty\",\n    \"The golden color makes it look like it tastes very good\",\n    \"Has a good taste\",\n    \"Low calorie and low carb.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T04:19:45.631907Z","iopub.execute_input":"2025-03-06T04:19:45.632217Z","iopub.status.idle":"2025-03-06T04:19:45.638450Z","shell.execute_reply.started":"2025-03-06T04:19:45.632191Z","shell.execute_reply":"2025-03-06T04:19:45.637340Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model.eval()\n\npairs = [[question, answer] for answer in answers]\n\nwith torch.no_grad():\n    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n    scores = model(**inputs, return_dict=True).logits.view(-1).float()\n\n\nprint(scores)\n\nmax_score = torch.max(scores)\nmin_score = torch.min(scores)\n\nmax_index = torch.argmax(scores).item()\nmin_index = torch.argmin(scores).item()\n\nprint(\"Max Score:\", max_score, \"at index:\", max_index)\nprint(\"Min Score:\", min_score, \"at index:\", min_index)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T03:39:20.564653Z","iopub.execute_input":"2025-03-06T03:39:20.564950Z","iopub.status.idle":"2025-03-06T03:39:43.056938Z","shell.execute_reply.started":"2025-03-06T03:39:20.564927Z","shell.execute_reply":"2025-03-06T03:39:43.056078Z"}},"outputs":[{"name":"stdout","text":"tensor([ -8.4176, -10.7068, -10.6932, -10.4330,  -9.8098, -10.9856, -10.9272,\n         -1.5391, -11.0181, -10.9624, -11.0195,  -9.7409, -11.0207, -10.9859,\n         -9.1820, -10.1955,  -9.2284,  -8.6836, -11.0087, -11.0083, -10.9640,\n         -7.4535,  -7.1470, -10.9776,  -8.5005,  -9.7899,  -6.2672, -10.6077,\n        -10.3079, -10.7164, -11.0189, -10.8767, -11.0364,  -8.4055, -10.0335,\n        -11.0283, -11.0205,  -7.3167, -10.9929,  -8.6696, -10.3186, -11.0116,\n        -11.0137, -10.4137, -10.7572,  -8.9085,  -7.3141,  -6.2694, -10.7229,\n        -11.0171,  -7.8104, -10.9029,  -9.1787, -10.9266, -10.2218, -11.0309,\n         -8.9989, -10.9968,  -6.6955, -11.0144, -10.6225, -10.1928, -10.9540,\n         -9.4952,  -8.5058, -10.5276, -11.0165,  -9.2103, -10.7932,  -9.9907,\n         -9.4738, -10.0742, -10.9843,  -8.4960, -10.7824, -10.9750, -10.7572,\n        -10.8384, -10.9213, -10.2958,  -8.1345, -10.8847])\nMax Score: tensor(-1.5391) at index: 7\nMin Score: tensor(-11.0364) at index: 32\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ndef get_inputs(pairs, tokenizer, prompt=None, max_length=1024):\n    if prompt is None:\n        prompt = \"Given a query A and a passage B, determine whether the passage contains an answer to the query by providing a prediction of either 'Yes' or 'No'.\"\n    sep = \"\\n\"\n    prompt_inputs = tokenizer(prompt,\n                              return_tensors=None,\n                              add_special_tokens=False)['input_ids']\n    sep_inputs = tokenizer(sep,\n                           return_tensors=None,\n                           add_special_tokens=False)['input_ids']\n    inputs = []\n    for query, passage in pairs:\n        query_inputs = tokenizer(f'A: {query}',\n                                 return_tensors=None,\n                                 add_special_tokens=False,\n                                 max_length=max_length * 3 // 4,\n                                 truncation=True)\n        passage_inputs = tokenizer(f'B: {passage}',\n                                   return_tensors=None,\n                                   add_special_tokens=False,\n                                   max_length=max_length,\n                                   truncation=True)\n        item = tokenizer.prepare_for_model(\n            [tokenizer.bos_token_id] + query_inputs['input_ids'],\n            sep_inputs + passage_inputs['input_ids'],\n            truncation='only_second',\n            max_length=max_length,\n            padding=False,\n            return_attention_mask=False,\n            return_token_type_ids=False,\n            add_special_tokens=False\n        )\n        item['input_ids'] = item['input_ids'] + sep_inputs + prompt_inputs\n        item['attention_mask'] = [1] * len(item['input_ids'])\n        inputs.append(item)\n    return tokenizer.pad(\n            inputs,\n            padding=True,\n            max_length=max_length + len(sep_inputs) + len(prompt_inputs),\n            pad_to_multiple_of=8,\n            return_tensors='pt',\n    )\n\ntokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-v2-gemma')\nmodel = AutoModelForCausalLM.from_pretrained('BAAI/bge-reranker-v2-gemma')\nyes_loc = tokenizer('Yes', add_special_tokens=False)['input_ids'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T04:26:21.272054Z","iopub.execute_input":"2025-03-06T04:26:21.272332Z","iopub.status.idle":"2025-03-06T04:27:37.846881Z","shell.execute_reply.started":"2025-03-06T04:26:21.272312Z","shell.execute_reply":"2025-03-06T04:27:37.846093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e8b67b07f144b678ee25c679b35babf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"138d1e58b499490f8c3ae885e00f7d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26e47acb65614ab2a025971c6592ca96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/555 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"160d16a719bf4a848ba6d3c09ee50c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"473a33b1ef99442eb02e330bef16604d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb56acb5972346d6aede3d33c167f5a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4340a6029a884433b72da779ab3ee157"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c723ac9204f5455eabf469948594f979"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f34a9a9971b4b9c87c376dc46ecca0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7b4d8d3d29d4a318103e5f8d5ad6243"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a663e922e2e44819e4ebb8cb8d94618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d61a6733e244e41a09078ff3e8f3610"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"!pip install -U FlagEmbedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:12:14.332411Z","iopub.execute_input":"2025-03-05T19:12:14.332715Z","iopub.status.idle":"2025-03-05T19:12:27.037059Z","shell.execute_reply.started":"2025-03-05T19:12:14.332694Z","shell.execute_reply":"2025-03-05T19:12:27.036215Z"}},"outputs":[{"name":"stdout","text":"Collecting FlagEmbedding\n  Downloading FlagEmbedding-1.3.4.tar.gz (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (2.5.1+cu121)\nRequirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (4.47.0)\nRequirement already satisfied: datasets>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (3.3.1)\nRequirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (1.2.1)\nRequirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (3.3.1)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (0.14.0)\nCollecting ir-datasets (from FlagEmbedding)\n  Downloading ir_datasets-0.5.9-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (0.2.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (3.20.3)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (6.0.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.29.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.0->FlagEmbedding) (3.11.12)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->FlagEmbedding) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->FlagEmbedding) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->FlagEmbedding) (0.21.0)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding) (4.12.3)\nCollecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding)\n  Downloading inscriptis-2.5.3-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->FlagEmbedding) (5.3.0)\nCollecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding)\n  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\nCollecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding)\n  Downloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding)\n  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\nCollecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding)\n  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding)\n  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding)\n  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding)\n  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (11.0.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding) (2.6)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2025.1.31)\nCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding)\n  Downloading cbor-1.0.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2025.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19.0->FlagEmbedding) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.20.1->FlagEmbedding) (2024.2.0)\nDownloading ir_datasets-0.5.9-py3-none-any.whl (347 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.9/347.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inscriptis-2.5.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\nDownloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\nDownloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\nDownloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nBuilding wheels for collected packages: FlagEmbedding, warc3-wet-clueweb09, cbor\n  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.3.4-py3-none-any.whl size=232500 sha256=e13df0e13756e28e80f513c16b696eca5212522c629fc388bf49ec673318d431\n  Stored in directory: /root/.cache/pip/wheels/59/8c/ba/90918a0fe0371cda2d087cffe7eb4bb4495409b6c67873a410\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=ebbd8ea448ab78d7c8d9cf0fc73d163265878e375de5ef16286ab399ed0a5cb1\n  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53430 sha256=a783201bbda00c32182bebd4d04cfe4bd21fe78a1c4322451014e224bb02eb5b\n  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\nSuccessfully built FlagEmbedding warc3-wet-clueweb09 cbor\nInstalling collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, inscriptis, trec-car-tools, ir-datasets, FlagEmbedding\nSuccessfully installed FlagEmbedding-1.3.4 cbor-1.0.0 ijson-3.3.0 inscriptis-2.5.3 ir-datasets-0.5.9 lz4-4.4.3 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model.eval()\npairs = [[question, answer] for answer in answers]\n\nwith torch.no_grad():\n    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n    scores = model(**inputs, return_dict=True).logits.view(-1).float()\n\n\nprint(scores)\n\nmax_score = torch.max(scores)\nmin_score = torch.min(scores)\n\nmax_index = torch.argmax(scores).item()\nmin_index = torch.argmin(scores).item()\n\nprint(\"Max Score:\", max_score, \"at index:\", max_index)\nprint(\"Min Score:\", min_score, \"at index:\", min_index)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from FlagEmbedding import FlagReranker\nreranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True)\n\nscore = reranker.compute_score(['query', 'passage'])\nprint(score)\n\nscore = reranker.compute_score(['query', 'passage'], normalize=True)\nprint(score)\n\nscores = reranker.compute_score(pairs)\nprint(scores)\n\nscores = reranker.compute_score(pairs , normalize=True)\nscores_list = scores.tolist()\n\nmax_score = max(scores_list)\nmin_score = min(scores_list)\n\nmax_index = scores_list.index(max_score)\nmin_index = scores_list.index(min_score)\n\nprint(\"Scores:\", scores_list)\nprint(\"Max Score:\", max_score, \"at index:\", max_index)\nprint(\"Min Score:\", min_score, \"at index:\", min_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T04:25:26.941849Z","iopub.execute_input":"2025-03-06T04:25:26.942154Z","iopub.status.idle":"2025-03-06T04:25:26.965728Z","shell.execute_reply.started":"2025-03-06T04:25:26.942131Z","shell.execute_reply":"2025-03-06T04:25:26.964704Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-ca0e121b8f0f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mFlagEmbedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlagReranker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreranker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlagReranker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BAAI/bge-reranker-v2-m3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreranker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'passage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'FlagEmbedding'"],"ename":"ModuleNotFoundError","evalue":"No module named 'FlagEmbedding'","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"import torch\n\ndef filter_scores(scores, threshold):\n    mask = scores > threshold  \n    filtered_scores = scores[mask]  \n    indices = torch.nonzero(mask).squeeze().tolist() \n\n    return filtered_scores, indices\n\n# Example usage\nscores = torch.tensor([\n    -8.4176, -10.7068, -10.6932, -10.4330, -9.8098, -10.9856, -10.9272,\n    -1.5391, -11.0181, -10.9624, -11.0195, -9.7409, -11.0207, -10.9859,\n    -9.1820, -10.1955, -9.2284, -8.6836, -11.0087, -11.0083, -10.9640,\n    -7.4535, -7.1470, -10.9776, -8.5005, -9.7899, -6.2672, -10.6077,\n    -10.3079, -10.7164, -11.0189, -10.8767, -11.0364, -8.4055, -10.0335,\n    -11.0283, -11.0205, -7.3167, -10.9929, -8.6696, -10.3186, -11.0116,\n    -11.0137, -10.4137, -10.7572, -8.9085, -7.3141, -6.2694, -10.7229,\n    -11.0171, -7.8104, -10.9029, -9.1787, -10.9266, -10.2218, -11.0309,\n    -8.9989, -10.9968, -6.6955, -11.0144, -10.6225, -10.1928, -10.9540,\n    -9.4952, -8.5058, -10.5276, -11.0165, -9.2103, -10.7932, -9.9907,\n    -9.4738, -10.0742, -10.9843, -8.4960, -10.7824, -10.9750, -10.7572,\n    -10.8384, -10.9213, -10.2958, -8.1345, -10.8847\n])\n\nthreshold = -12.0\n\nfiltered_scores, indices = filter_scores(scores, threshold)\n\nprint(\"Filtered Scores:\", filtered_scores)\nprint(\"Indices:\", indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T04:21:41.416837Z","iopub.execute_input":"2025-03-06T04:21:41.417134Z","iopub.status.idle":"2025-03-06T04:21:41.427511Z","shell.execute_reply.started":"2025-03-06T04:21:41.417111Z","shell.execute_reply":"2025-03-06T04:21:41.426702Z"}},"outputs":[{"name":"stdout","text":"Filtered Scores: tensor([ -8.4176, -10.7068, -10.6932, -10.4330,  -9.8098, -10.9856, -10.9272,\n         -1.5391, -11.0181, -10.9624, -11.0195,  -9.7409, -11.0207, -10.9859,\n         -9.1820, -10.1955,  -9.2284,  -8.6836, -11.0087, -11.0083, -10.9640,\n         -7.4535,  -7.1470, -10.9776,  -8.5005,  -9.7899,  -6.2672, -10.6077,\n        -10.3079, -10.7164, -11.0189, -10.8767, -11.0364,  -8.4055, -10.0335,\n        -11.0283, -11.0205,  -7.3167, -10.9929,  -8.6696, -10.3186, -11.0116,\n        -11.0137, -10.4137, -10.7572,  -8.9085,  -7.3141,  -6.2694, -10.7229,\n        -11.0171,  -7.8104, -10.9029,  -9.1787, -10.9266, -10.2218, -11.0309,\n         -8.9989, -10.9968,  -6.6955, -11.0144, -10.6225, -10.1928, -10.9540,\n         -9.4952,  -8.5058, -10.5276, -11.0165,  -9.2103, -10.7932,  -9.9907,\n         -9.4738, -10.0742, -10.9843,  -8.4960, -10.7824, -10.9750, -10.7572,\n        -10.8384, -10.9213, -10.2958,  -8.1345, -10.8847])\nIndices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n","output_type":"stream"}],"execution_count":13}]}